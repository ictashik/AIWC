{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0623af7d",
      "metadata": {},
      "source": [
        "# Day 2: Basic ML Concepts & Dataset Exploration\n",
        "\n",
        "Welcome to **Day 2** of our elective: **AI in White Coat**. Today, we’ll build on our HPC familiarity and start diving into **core ML concepts** and **practical dataset exploration**. By the end of this session, you’ll:\n",
        "\n",
        "1. Understand basic ML terminology (classification vs. regression).\n",
        "2. Practice a *prompt-first* approach to load and explore a small open-source dataset from [Hugging Face](https://huggingface.co/datasets).\n",
        "3. Perform a simple train/test split and build a baseline classifier (e.g., Logistic Regression).\n",
        "4. Evaluate your model’s accuracy and examine a confusion matrix.\n",
        "\n",
        "---\n",
        "## 1. Quick Recap of Day 1\n",
        "- We learned how to log in to our HPC at `10.20.110.114`.\n",
        "- We tried out basic Linux commands and verified GPU availability.\n",
        "- We also practiced a \"prompt-first\" approach using an LLM.\n",
        "\n",
        "If you haven’t already, please create or navigate to your `day2_notebook` folder on the HPC. Let’s get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14ff2c04",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5b6fdb0c",
      "metadata": {},
      "source": [
        "## 2. Classification vs. Regression (Conceptual Overview)\n",
        "\n",
        "In **Machine Learning**, we often distinguish between:\n",
        "- **Classification**: Predicting discrete labels (e.g., disease vs. no disease, normal vs. abnormal imaging). \n",
        "- **Regression**: Predicting continuous values (e.g., a patient’s blood pressure, hospital length of stay).\n",
        "\n",
        "### Clinical Examples\n",
        "- **Classification**: Is a given chest X-ray indicative of pneumonia (Yes/No)?\n",
        "- **Regression**: Estimate a patient’s ejection fraction (a % measurement) based on various inputs.\n",
        "\n",
        "Today, we’ll do a **classification** example using a small dataset from Hugging Face. In future sessions, we’ll explore more advanced or specialized tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9429ef",
      "metadata": {},
      "source": [
        "## 3. Installing and Importing Libraries (Prompt-First)\n",
        "\n",
        "On some HPCs, libraries like `datasets`, `numpy`, `scikit-learn`, etc., might not be installed by default. You may need to prompt the LLM for an installation script.\n",
        "\n",
        "### Example Prompt\n",
        "```\n",
        "I am on a remote HPC (Ubuntu). I have Python 3 and pip.\n",
        "Please generate a shell command to:\n",
        "1. Upgrade pip\n",
        "2. Install datasets, scikit-learn, numpy, matplotlib\n",
        "```\n",
        "\n",
        "After receiving the shell command from the LLM, run it in your terminal or as a cell magic (e.g., `!pip install ...`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d25aae0f",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Install Dependencies) ======\n",
        "# If these libraries are already installed, you can skip or comment this out.\n",
        "# Example:\n",
        "# !pip install --upgrade pip\n",
        "# !pip install datasets scikit-learn numpy matplotlib\n",
        "\n",
        "# Uncomment or paste your LLM output here if needed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "932e9ebc",
      "metadata": {},
      "source": [
        "Now let’s **import** our libraries. If something is missing, prompt the LLM for troubleshooting help or re-install the relevant package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad9fa70a",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# ====== Python Imports (adjust as needed) ======\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"Imports complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ecdee5bf",
      "metadata": {},
      "source": [
        "## 4. Loading a Sample Dataset from Hugging Face\n",
        "\n",
        "Let’s pick a small tabular or image dataset for a classification demonstration. One option is the [*Banking77*](https://huggingface.co/datasets/banking77) dataset (intent classification of banking queries). Another could be a small image dataset like [*beans*](https://huggingface.co/datasets/beans) (healthy vs. diseased leaves). \n",
        "\n",
        "### Prompt Example\n",
        "```\n",
        "I want to load the \"beans\" dataset from Hugging Face in a Python notebook.\n",
        "Please generate code using the 'datasets' library.\n",
        "Then show how to explore the dataset (like printing a few samples).\n",
        "```\n",
        "\n",
        "We'll do it step by step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "214b65a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Load Dataset) ======\n",
        "# Paste your prompt's result here. Example:\n",
        "\n",
        "beans = load_dataset(\"beans\")\n",
        "print(beans)\n",
        "\n",
        "# Let's see a sample:\n",
        "sample = beans['train'][0]\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d4fa19",
      "metadata": {},
      "source": [
        "Depending on which dataset you choose, you’ll see its **train/test/validation** splits and some sample features. For image datasets, it might store pixel values or file paths.\n",
        "\n",
        "### Quick Exploration\n",
        "- Check the number of samples in each split.\n",
        "- Look at a few random samples to see the labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adaeb379",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Exploration) ======\n",
        "# Example prompt:\n",
        "# \"Please show me code to shuffle the dataset, take a random sample, and display the label.\"\n",
        "# Then paste the code below.\n",
        "\n",
        "print(\"Train size:\", len(beans['train']))\n",
        "print(\"Validation size:\", len(beans['validation']))\n",
        "print(\"Test size:\", len(beans['test']))\n",
        "\n",
        "# Example random sample\n",
        "import random\n",
        "rand_index = random.randint(0, len(beans['train']) - 1)\n",
        "random_sample = beans['train'][rand_index]\n",
        "random_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "023cbb3b",
      "metadata": {},
      "source": [
        "## 5. From Dataset to Numpy Arrays (or Tensors)\n",
        "\n",
        "Many ML algorithms (like scikit-learn’s Logistic Regression) expect numeric arrays. For image data, we may flatten or preprocess images. For text data, we may tokenize. \n",
        "\n",
        "Here, let’s do a **simple approach**:\n",
        "1. Convert images into flattened arrays (if it’s an image dataset). Or if we’re dealing with tabular data, select the relevant features.\n",
        "2. Convert labels to numeric form.\n",
        "\n",
        "**Note**: This is a simplified example. For more complex tasks (e.g., deep learning on images), you’d likely use a framework like PyTorch or TensorFlow with specialized data loaders.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a1271dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Data Conversion) ======\n",
        "# Example prompt:\n",
        "# \"Please generate code to convert the Hugging Face image dataset into flattened numpy arrays and numeric labels\"\n",
        "\n",
        "def dataset_to_arrays(dataset_dict):\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    for item in dataset_dict:\n",
        "        image_np = np.array(item['image']).flatten()  # Flatten\n",
        "        label = item['labels']  # or item['label'] depending on dataset\n",
        "        X_list.append(image_np)\n",
        "        y_list.append(label)\n",
        "    return np.array(X_list), np.array(y_list)\n",
        "\n",
        "# Convert train/validation/test splits.\n",
        "X_train, y_train = dataset_to_arrays(beans['train'])\n",
        "X_val, y_val = dataset_to_arrays(beans['validation'])\n",
        "X_test, y_test = dataset_to_arrays(beans['test'])\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4af47cd7",
      "metadata": {},
      "source": [
        "## 6. Building a Simple Classifier\n",
        "\n",
        "We’ll do a **Logistic Regression** as our baseline classifier. Although it’s not typically used for raw images, this is just to demonstrate the ML workflow:\n",
        "1. **Fit** a classifier on `(X_train, y_train)`.\n",
        "2. **Validate** on `(X_val, y_val)` (optional, but good practice).\n",
        "3. **Test** final performance on `(X_test, y_test)`.\n",
        "\n",
        "### Train-Test Split Example (Alternative)\n",
        "If your dataset doesn't have separate splits, you can manually create them using `train_test_split` from scikit-learn. For example:\n",
        "```\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
        "```\n",
        "\n",
        "Let’s proceed with the dataset’s default splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59e53e23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Logistic Regression) ======\n",
        "# Example prompt:\n",
        "# \"Generate code to train a LogisticRegression model on (X_train, y_train),\n",
        "# evaluate it on (X_val, y_val), then test on (X_test, y_test). Print accuracy.\"\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Validation Phase\")\n",
        "val_preds = clf.predict(X_val)\n",
        "val_acc = accuracy_score(y_val, val_preds)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "print(\"\\nTest Phase\")\n",
        "test_preds = clf.predict(X_test)\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "print(\"Test Accuracy:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cd54f3d",
      "metadata": {},
      "source": [
        "## 7. Evaluating with a Confusion Matrix\n",
        "\n",
        "A **confusion matrix** helps visualize how many items were correctly classified vs. misclassified for each class.\n",
        "\n",
        "### Prompt Example\n",
        "```\n",
        "Please generate a code snippet that computes a confusion matrix\n",
        "for test_preds and y_test using scikit-learn.\n",
        "Then display it using matplotlib.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4be04408",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ====== LLM-GENERATED CODE CELL (Confusion Matrix) ======\n",
        "# Example:\n",
        "\n",
        "cm = confusion_matrix(y_test, test_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "plt.matshow(cm, cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1f331f",
      "metadata": {},
      "source": [
        "## 8. Observations & Clinical Relevance\n",
        "\n",
        "- **Model Performance**: Logistic Regression on raw images might not yield very high accuracy, but this is a simplified demonstration.\n",
        "- **Why It Matters**: Even a basic workflow reveals the process of training, validating, testing, and interpreting results. In real-world practice, you’d consider deep CNNs or specialized architectures for images.\n",
        "- **Next Steps**: We’ll explore more sophisticated models or domain-specific techniques in future sessions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9ff54e7",
      "metadata": {},
      "source": [
        "## 9. Assignment #2: A Deeper Dive\n",
        "\n",
        "**Task**: Using the same dataset (or a different open-source dataset if you wish):\n",
        "1. **Perform an Extended EDA** (Exploratory Data Analysis). \n",
        "   - Prompt the LLM to generate code that computes class distribution, plots a few images (if image data), or prints summary statistics.\n",
        "2. **Try a Different Classifier** (e.g., `RandomForestClassifier` from scikit-learn) and compare accuracy with Logistic Regression.\n",
        "3. **Document** your findings in your daily log:\n",
        "   - How does the confusion matrix differ?\n",
        "   - Which classes are easiest/hardest to predict?\n",
        "\n",
        "### Bonus\n",
        "- Use an LLM to **optimize hyperparameters** (e.g., number of estimators in RandomForest) and see if performance improves.\n",
        "- Reflect on how you might apply these methods to actual medical images or clinical data.\n",
        "\n",
        "**Feel free to add** any interesting observations or creative solutions. Good luck, and see you on **Day 3**!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af926c25",
      "metadata": {},
      "source": [
        "# End of Day 2 Notebook\n",
        "\n",
        "Today, you learned how to:\n",
        "- Install and import necessary libraries.\n",
        "- Load a dataset from Hugging Face.\n",
        "- Convert data to a format suitable for scikit-learn.\n",
        "- Train, evaluate, and interpret a baseline classifier.\n",
        "\n",
        "Remember to record your progress, roadblocks, and reflections in your **Daily Log** or **Portfolio**. If you have questions, ask your mentors or consult the LLM for additional guidance!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
